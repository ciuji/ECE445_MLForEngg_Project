{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Friday--Cluster\n",
    "\n",
    "## dataset description\n",
    "\n",
    "\"Dataset of 550 000 observations about the black Friday in a retail store, it contains different kinds of variables either numerical or categorical. It contains missing values.\"\n",
    "\n",
    "## raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
      "324155  1001891  P00345742      M  46-50           1             C   \n",
      "384692  1005193  P00084842      M  36-45          12             B   \n",
      "34262   1005282  P00183642      F  18-25           4             B   \n",
      "328396  1002590  P00128342      M  18-25           4             A   \n",
      "270293  1005650  P00367042      F  36-45          12             B   \n",
      "\n",
      "       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
      "324155                          3               1                   1   \n",
      "384692                          2               1                   8   \n",
      "34262                           1               1                   4   \n",
      "328396                          0               0                   5   \n",
      "270293                          2               1                   8   \n",
      "\n",
      "        Product_Category_2  Product_Category_3  Purchase  \n",
      "324155                 2.0                15.0     11700  \n",
      "384692                16.0                 NaN      6051  \n",
      "34262                  5.0                 9.0       766  \n",
      "328396                12.0                14.0      3480  \n",
      "270293                 NaN                 NaN      6164  \n"
     ]
    }
   ],
   "source": [
    "df_allData=pd.read_csv('BlackFriday.csv')\n",
    "print(df_allData.sample(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw data has 12 columns and there are a lot of missing values in \"Product_Category_2\" and \"Product_Category_3\". Which means some of the product whould just have one category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our opinion, we think our model would do cluster on different people, so our key is people.\n",
    "\n",
    "But the dataset includes different records of one-single people. So at the beginning we use gruopby to get each people's whole records. \n",
    "\n",
    "Then we try to get the mode of each one's \"Product_Category_1\" to represent the main product category and get the mean of one people's whole \"Purchase\" as a feature of \"average purchase\". (We are not sure weather this is a good way buy we have to do this because we cannot keep all the data to train)\n",
    "\n",
    "What's more, we change the \"Gender\" attribute to 0-1 attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Occupation    Age City_Category  Marital_Status  Product_CateGory_1  \\\n",
      "User_ID                                                                        \n",
      "1004956          15  36-45             B               1                   8   \n",
      "1000839           0  26-35             A               0                   8   \n",
      "1003510           4  18-25             B               1                   5   \n",
      "1003016          12  18-25             A               0                   1   \n",
      "1005555          10   0-17             B               0                   1   \n",
      "\n",
      "        Stay_In_Current_City_Years  times  Gender_M      Purchase  \n",
      "User_ID                                                            \n",
      "1004956                          1    120         1   9324.600000  \n",
      "1000839                          2    435         1  10761.390805  \n",
      "1003510                          1     32         0   9913.406250  \n",
      "1003016                          1     18         1  11067.111111  \n",
      "1005555                          2    276         1   9055.329710  \n"
     ]
    }
   ],
   "source": [
    "groupByUserData=df_allData.groupby(['User_ID'])\n",
    "\n",
    "times=df_allData['User_ID'].value_counts()\n",
    "times=times.sort_index()\n",
    "\n",
    "#get the mean\n",
    "meanData=groupByUserData.mean()\n",
    "\n",
    "#get the mode\n",
    "modeData=groupByUserData.agg(lambda x: stats.mode(x)[0][0])\n",
    "\n",
    "mean_mode_data={'Gender':modeData['Gender'],'Occupation':modeData['Occupation'],'Age':modeData['Age'],'City_Category':modeData['City_Category'],'Marital_Status':modeData['Marital_Status'],'Product_CateGory_1':modeData['Product_Category_1'],'Stay_In_Current_City_Years':modeData['Stay_In_Current_City_Years']}\n",
    "mean_mode_data=pd.DataFrame(mean_mode_data)\n",
    "mean_mode_data['times']=times\n",
    "mean_mode_data['Gender_M']=pd.get_dummies(mean_mode_data['Gender'])['M']\n",
    "mean_mode_data=mean_mode_data.drop(['Gender'],axis=1)\n",
    "mean_mode_data['Purchase']=meanData['Purchase']\n",
    "\n",
    "print (mean_mode_data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the hardest part of our cluster project.\n",
    "\n",
    "There are two key problems we have to face:\n",
    "\n",
    "##### 1. **how to handle the discrete attributes?**\n",
    "    \n",
    "    There are a lot of disordered discrete attributes in our data, likes \"Marital_Status\", \"Gender\" and \"Product_Category_1\", we cannot just simplely calculate their euclidean distance.\n",
    "\n",
    "##### 2. **how to evaluate our feature extraction performance?**\n",
    "\n",
    "    Since we have so many choices of extracting the features and we do not know how to assign the weights on these feautres and this is a cluster problem, we had not a clearly mind of have to evaluate our work when we doing the feature extraction. And it is unrealistic to try all the choices and train them then evaluate the final models. The best solution is that we can find some explainable output of our feature extraction.\n",
    "    \n",
    "#### deal with discrete attributes\n",
    "\n",
    "To solve the key problems 1, we came up with ideas.\n",
    "\n",
    "1. do one-hot encoding on the discrete attributes\n",
    "\n",
    "1. use Value Difference Metric to calculate the distance\n",
    "\n",
    "1. use k-modes or k-prototype model\n",
    "\n",
    "But their would raise some new problems if we use these solutions:\n",
    "\n",
    "    one-hot encoding would make the features very sparse.\n",
    "    \n",
    "    It is not easy to combine the VDM distance and Minkowski distance together.\n",
    "    \n",
    "    Some discrete features may be very important like occupation but it would have a lot of possible value.\n",
    "    \n",
    "#### deal with evaluation\n",
    "\n",
    "We do not find a good way to solve this problem, we just living with it, but we still did some tries. Likes using the average purchase to evaluate the cluster output. And we use Calinski-Harabasz score to evalue our final clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pre-processing before training\n",
    "\n",
    "Since we have features of different units, we must do the data standardization and assign different weights to different features.\n",
    "\n",
    "We choose min-max standardization and assign the weights by feeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
